#version 460
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_scalar_block_layout : require
#extension GL_EXT_nonuniform_qualifier : require
#extension GL_EXT_shader_explicit_arithmetic_types : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
#extension GL_EXT_shader_explicit_arithmetic_types_int32 : require
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_vote : require
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_KHR_shader_subgroup_shuffle : require
#extension GL_EXT_shader_atomic_float : require

#ifdef VALIDATE
#extension GL_EXT_debug_printf : enable
#endif

#define SHADER_CONST const
#include "rlpbr_core/device.h"
#undef SHADER_CONST

#include "comp_definitions.h"
#include "utils.glsl"

layout (set = 0, binding = 0, scalar) buffer TonemapIlluminance {
    float illuminanceBuffer[];
};

layout (set = 0, binding = 1, scalar) buffer Input {
    float inputBuffer[];
};

layout (set = 0, binding = 2, scalar) buffer Output {
    uint32_t outputBuffer[];
};

vec3 getInput(uint32_t base_offset, out uint32_t instance_id)
{
    float r = inputBuffer[nonuniformEXT(base_offset)];
    float g = inputBuffer[nonuniformEXT(base_offset + 1)];
    float b = inputBuffer[nonuniformEXT(base_offset + 2)];
    float inst_f = inputBuffer[nonuniformEXT(base_offset + 1)];

    instance_id = floatBitsToUint(inst_f);

    return vec3(r, g, b);
}

void setOutput(uint32_t base_offset, vec3 rgb, uint32_t instance_id)
{
    rgb = min(rgb, vec3(65504.f));

    uint32_t ab = packHalf2x16(rgb.xy);
    uint32_t cd = packHalf2x16(vec2(rgb.z, 0));
    cd |= instance_id << 16;

    outputBuffer[nonuniformEXT(base_offset)] = ab;
    outputBuffer[nonuniformEXT(base_offset + 1)] = cd;
}

// Aplies exponential ("Photographic") luma compression
float rangeCompress(float x)
{
    return 1.0 - exp(-x);
}

float rangeCompress(float val, float threshold)
{
    float v1 = val;
    float v2 = threshold + (1 - threshold) * rangeCompress((val - threshold) / (1 - threshold));
    return val < threshold ? v1 : v2;
}

vec3 rangeCompress(vec3 val, float threshold)
{
    return vec3(
        rangeCompress(val.x, threshold),
        rangeCompress(val.y, threshold),
        rangeCompress(val.z, threshold));
}

// RGB with sRGB/Rec.709 primaries to CIE XYZ
vec3 RGBToXYZ(vec3 c)
{
    mat3 mat = mat3(
        vec3(0.4124564, 0.2126729, 0.0193339),
        vec3(0.3575761, 0.7151522, 0.1191920),
        vec3(0.1804375, 0.0721750, 0.9503041));

    return mat * c;
}

vec3 XYZToRGB(vec3 c)
{
    mat3 mat = mat3(
        vec3(3.24045483602140870, -0.96926638987565370, 0.05564341960421366),
        vec3(-1.53713885010257510, 1.87601092884249100, -0.20402585426769815),
        vec3(-0.49853154686848090, 0.04155608234667354, 1.05722516245792870));

    return mat * c;
}

// Converts XYZ tristimulus values into cone responses for the three types of cones in the human visual system, matching long, medium, and short wavelengths.
// Note that there are many LMS color spaces; this one follows the ICtCp color space specification.
vec3 XYZToLMS(vec3 c)
{
    mat3 mat = mat3(
        vec3(0.3592, -0.1922, 0.0070),
        vec3(0.6976, 1.1004, 0.0749),
        vec3(-0.0358, 0.0755, 0.8434));

    return mat * c;
}

vec3 LMSToXYZ(vec3 c)
{
    mat3 mat = mat3(
        vec3(2.07018005669561320, 0.36498825003265756, -0.04959554223893212),
        vec3(-1.32645687610302100, 0.68046736285223520, -0.04942116118675749),
        vec3(0.206616006847855170, -0.045421753075853236, 1.187995941732803400));

    return mat * c;
}

const float PQ_constant_N = (2610.0 / 4096.0 / 4.0);
const float PQ_constant_M = (2523.0 / 4096.0 * 128.0);
const float PQ_constant_C1 = (3424.0 / 4096.0);
const float PQ_constant_C2 = (2413.0 / 4096.0 * 32.0);
const float PQ_constant_C3 = (2392.0 / 4096.0 * 32.0);

// PQ (Perceptual Quantiser; ST.2084) encode/decode used for HDR TV and grading
vec3 linearToPQ(vec3 linearCol, const float maxPqValue)
{
    linearCol /= maxPqValue;

    vec3 colToPow = pow(linearCol, vec3(PQ_constant_N));
    vec3 numerator = PQ_constant_C1 + PQ_constant_C2*colToPow;
    vec3 denominator = vec3(1.0) + PQ_constant_C3*colToPow;
    vec3 pq = pow(numerator / denominator, vec3(PQ_constant_M));

    return pq;
}

vec3 PQtoLinear(vec3 linearCol, const float maxPqValue)
{
    vec3 colToPow = pow(linearCol, vec3(1.0 / PQ_constant_M));
    vec3 numerator = max(colToPow - PQ_constant_C1, vec3(0.0));
    vec3 denominator = PQ_constant_C2 - (PQ_constant_C3 * colToPow);
    vec3 linearColor = pow(numerator / denominator, vec3(1.0 / PQ_constant_N));

    linearColor *= maxPqValue;

    return linearColor;
}

// RGB with sRGB/Rec.709 primaries to ICtCp
vec3 RGBToICtCp(vec3 col)
{
    col = RGBToXYZ(col);
    col = XYZToLMS(col);
    // 1.0f = 100 nits, 100.0f = 10k nits
    col = linearToPQ(max(vec3(0.f), col), 100.0);

    // Convert PQ-LMS into ICtCp. Note that the "S" channel is not used,
    // but overlap between the cone responses for long, medium, and short wavelengths
    // ensures that the corresponding part of the spectrum contributes to luminance.

    mat3 mat = mat3(
        vec3(0.5000, 1.6137, 4.3780),
        vec3(0.5000, -3.3234, -4.2455),
        vec3(0.0000, 1.7097, -0.1325));

    return mat * col;
}

vec3 ICtCpToRGB(vec3 col)
{
    mat3 mat = mat3(
        vec3(1.0, 1.0, 1.0),
        vec3(0.00860514569398152, -0.00860514569398152, 0.56004885956263900),
        vec3(0.11103560447547328, -0.11103560447547328, -0.32063747023212210));

    col = mat * col;

    // 1.0f = 100 nits, 100.0f = 10k nits
    col = PQtoLinear(col, 100.0);
    col = LMSToXYZ(col);
    return XYZToRGB(col);
}

vec3 applyHuePreservingShoulder(vec3 col)
{
    vec3 ictcp = RGBToICtCp(col);

    // Hue-preserving range compression requires desaturation in order to achieve a natural look. We adaptively desaturate the input based on its luminance.
    float saturationAmount = pow(smoothstep(1.0f, 0.3f, ictcp.x), 1.3f);
    col = ICtCpToRGB(ictcp * vec3(1, saturationAmount, saturationAmount));

    // Only compress luminance starting at a certain point. Dimmer inputs are passed through without modification.
    float linearSegmentEnd = 0.25;

    // Hue-preserving mapping
    float maxCol = max(col.x, max(col.y, col.z));
    float mappedMax = rangeCompress(maxCol, linearSegmentEnd);
    vec3 compressedHuePreserving = col * mappedMax / maxCol;

    // Non-hue preserving mapping
    vec3 perChannelCompressed = rangeCompress(col, linearSegmentEnd);

    // Combine hue-preserving and non-hue-preserving colors. Absolute hue preservation looks unnatural, as bright colors *appear* to have been hue shifted.
    // Actually doing some amount of hue shifting looks more pleasing
    col = mix(perChannelCompressed, compressedHuePreserving, 0.6f);

    vec3 ictcpMapped = RGBToICtCp(col);

    // Smoothly ramp off saturation as brightness increases, but keep some even for very bright input
    float postCompressionSaturationBoost = 0.3f * smoothstep(1.f, 0.5f, ictcp.x);

    // Re-introduce some hue from the pre-compression color. Something similar could be accomplished by delaying the luma-dependent desaturation before range compression.
    // Doing it here however does a better job of preserving perceptual luminance of highly saturated colors. Because in the hue-preserving path we only range-compress the max channel,
    // saturated colors lose luminance. By desaturating them more aggressively first, compressing, and then re-adding some saturation, we can preserve their brightness to a greater extent.
    vec2 orig_chroma = vec2(ictcpMapped.y, ictcpMapped.z);
    vec2 chroma_shift = mix(orig_chroma, orig_chroma * ictcpMapped.x / max(1e-3f, ictcp.x), postCompressionSaturationBoost);

    ictcpMapped.y = chroma_shift.x;
    ictcpMapped.z = chroma_shift.y;

    col = ICtCpToRGB(ictcpMapped);

    return col;
}

vec3 eaTonemap(vec3 v)
{
    return clamp(applyHuePreservingShoulder(v), 0, 1);
}

vec3 UC2Tonemap(vec3 v)
{
    const float A = 0.15;
    const float B = 0.50;
    const float C = 0.10;
    const float D = 0.20;
    const float E = 0.02;
    const float F = 0.30;
    const float W = 1.2;

    vec3 tonemapped = ((v * (A * v + C * B) + D * E) /
                       (v * (A * v + B) + D * F)) - E / F;

    const float tonemap_W = ((W * (A * W + C * B) + D * E) /
                             (W * (A * W + B) + D * F)) - E / F;

    const float whitescale = 1.f / tonemap_W;

    tonemapped *= whitescale;

    return clamp(tonemapped, 0, 1);
}

// Modified from
// https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl
// MIT License: Stephen Hill
vec3 RRTAndODTFit(vec3 v)
{
    vec3 a = v * (v + 0.0245786f) - 0.000090537f;
    vec3 b = v * (0.983729f * v + 0.4329510f) + 0.238081f;
    return a / b;
}

vec3 ACESFitted(vec3 v)
{
    const mat3 input_mat = mat3(
        vec3(0.59719, 0.07600, 0.02840),
        vec3(0.35458, 0.90834, 0.13383),
        vec3(0.04823, 0.01566, 0.83777));

    const mat3 output_mat = mat3(
        vec3(1.60475, -0.10208, -0.00327),
        vec3(-0.53108, 1.10813, -0.07276),
        vec3(-0.07367, -0.00605, 1.07602));

    v = input_mat * v;

    v = RRTAndODTFit(v);

    v = output_mat * v;

    return clamp(v, 0, 1);
}

vec3 reinhard(vec3 v)
{
    float l = rgbToLuminance(v);

    float white = 5;

    float t = l * (1.f + (l / (white * white))) / (1.f + l);

    return clamp(v * t / l, 0, 1);
}

// GDC 2016: Advanced Techniques and Optimization of VDR Color Pipelines
vec3 lottes(vec3 v)
{
    const float contrast = 0.31f;
    const float shoulder = -6.6f;
    const float mid_in = 0.18;
    const float mid_out = 0.1;
    const float hdr_max = 1.2f;

    const float b =
        (-pow(mid_in, contrast) + pow(hdr_max, contrast) * mid_out) /
        ((pow(hdr_max, contrast * shoulder) -
            pow(mid_in, contrast * shoulder)) * mid_out);

    const float c = (pow(hdr_max, contrast * shoulder) * pow(mid_in, contrast) -
                        pow(hdr_max, contrast) *
                            pow(mid_in, contrast * shoulder) * mid_out) / 
                    ((pow(hdr_max, contrast * shoulder) -
                        pow(mid_in, contrast * shoulder)) * mid_out);

    float peak = max(max(v.x, v.y), v.z);

    vec3 ratio = v / peak;

    float z = pow(peak, contrast);

    float y = z / (pow(z, shoulder) * b + c);

    return clamp(y * ratio, 0, 1);
}

layout (local_size_x = LOCAL_WORKGROUP_X,
        local_size_y = LOCAL_WORKGROUP_Y,
        local_size_z = LOCAL_WORKGROUP_Z) in;
void main()
{
    uint32_t batch_idx = gl_GlobalInvocationID.z;
    u32vec2 xy_idx = gl_GlobalInvocationID.xy;

    if (xy_idx.x >= RES_X || xy_idx.y >= RES_Y) {
        return;
    }

    float exposure = illuminanceBuffer[batch_idx];

    uint32_t input_idx = 4 * (
        batch_idx * RES_Y * RES_X + xy_idx.y * RES_X + xy_idx.x);

    uint32_t output_idx = 2 * (
        batch_idx * RES_Y * RES_X + xy_idx.y * RES_X + xy_idx.x);

    uint32_t instance_id;
    vec3 untonemapped = getInput(input_idx, instance_id);

/*
    vec3 exposed = untonemapped * exposure;

    vec3 tonemapped = eaTonemap(exposed);
    */

    setOutput(output_idx, untonemapped, instance_id);
}
